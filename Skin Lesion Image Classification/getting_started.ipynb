{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e498c-2b63-49bb-b1e5-68d40e3d8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0987e3d-2129-459d-8497-94023f318862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-addons\n",
    "\n",
    "import lesion_data\n",
    "import augmentor\n",
    "import constants\n",
    "import cropper \n",
    "import splitter\n",
    "\n",
    "from lesion_data import LesionData\n",
    "from augmentor import Augmentor\n",
    "from importlib import reload\n",
    "\n",
    "reload(lesion_data);\n",
    "reload(augmentor);\n",
    "reload(constants)\n",
    "reload(cropper)\n",
    "reload(splitter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9bc32e0-75b8-46ca-b2e5-718b65c7d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Stage\n",
    "data = LesionData()\n",
    "data.download_and_unzip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fb4e398-0d3a-4d64-9629-ac8dd6164986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function gaussian_filter2d at 0x7f2779a88b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Done cropping all images. Cropped Path isic_data/ISIC_2019_Training_Cropped\n"
     ]
    }
   ],
   "source": [
    "# Crop Stage \n",
    "cropper = Cropper()\n",
    "cropper.crop_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df5d3ccd-9547-4df5-9e68-6d7cd0d237f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up isic_data/Training_Split\n",
      "Cleaning up isic_data/Test_Split\n",
      "Cleaning up isic_data/Test_Split\n"
     ]
    }
   ],
   "source": [
    "# Split \n",
    "sp = splitter.Splitter()\n",
    "sp.split_train_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84e93f95-4ade-41e0-8e87-572add1c9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up isic_data/ISIC_2019_Training_Augmented_250\n",
      "Start processing class: MEL\n",
      "Start processing class: NV\n",
      "Start processing class: BCC\n",
      "Start processing class: AK\n",
      "(NV) --> len(all_images)=9251, count=250, subsetting without augmentation.\n",
      "(MEL) --> len(all_images)=3261, count=250, subsetting without augmentation.\n",
      "(BCC) --> len(all_images)=2383, count=250, subsetting without augmentation.\n",
      "(AK) --> len(all_images)=635, count=250, subsetting without augmentation.\n",
      "(NV) --> Done with downsampling class NV.\n",
      "Start processing class: BKL\n",
      "(BKL) --> len(all_images)=1902, count=250, subsetting without augmentation.\n",
      "(AK) --> Done with downsampling class AK.\n",
      "Start processing class: DF\n",
      "(DF) --> len(all_images)=178, count=250, augmenting up to required count.\n",
      "(BCC) --> Done with downsampling class BCC.\n",
      "Start processing class: VASC\n",
      "(VASC) --> len(all_images)=185, count=250, augmenting up to required count.\n",
      "(MEL) --> Done with downsampling class MEL.\n",
      "Start processing class: SCC\n",
      "(SCC) --> len(all_images)=444, count=250, subsetting without augmentation.\n",
      "(BKL) --> Done with downsampling class BKL.\n",
      "Skipping UNK\n",
      "(SCC) --> Done with downsampling class SCC.\n",
      "(VASC) --> Done with augmenting class VASC.\n",
      "(DF) --> Done with augmenting class DF.\n"
     ]
    }
   ],
   "source": [
    "reload(augmentor)\n",
    "reload(constants)\n",
    "\n",
    "# Load Training augmented data for Count 250 \n",
    "count = 250\n",
    "path = constants.get_training_augmented_path_with_count_suffix(count=count)\n",
    "aug = augmentor.Augmentor(dir_path=path)\n",
    "aug.augment(count)\n",
    "\n",
    "# Return all images in a np.Array \n",
    "x_train, y_train = aug.get_numpy_data()\n",
    "\n",
    "# Load validation data in np.Array. To limit the num of images loaded pass limit=250\n",
    "x_val, y_val  = constants.load_validation_split_data_with_labels()\n",
    "\n",
    "# Load Test data in np.Array.  To limit the num of images loaded pass limit=250\n",
    "x_test, y_test = constants.load_testing_split_data_with_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07d18c3e-6a9a-4bb4-a490-d917710610c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.len=2000\n",
      "y_train.len=2000\n",
      "x_train.shape=(2000, 244, 244, 3)\n",
      "y_train.shape=(2000, 8)\n",
      "x_test.len=5066\n",
      "y_test.len=5066\n",
      "x_test.shape=(5066, 244, 244, 3)\n",
      "y_test.shape=(5066, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.len=\" + str(len(x_train)))\n",
    "print(\"y_train.len=\" + str(len(y_train)))\n",
    "\n",
    "print(\"x_train.shape=\" + str(x_train.shape))\n",
    "print(\"y_train.shape=\" + str(y_train.shape))\n",
    "\n",
    "print(\"x_test.len=\" + str(len(x_test)))\n",
    "print(\"y_test.len=\" + str(len(y_test)))\n",
    "\n",
    "print(\"x_test.shape=\" + str(x_test.shape))\n",
    "print(\"y_test.shape=\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65fddcc7-c546-402b-aa3f-808c806d4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up isic_data/Test_Split_class\n",
      "Skipping UNK\n"
     ]
    }
   ],
   "source": [
    "# For validation and test data, because it's not being augmented, we need to manually \n",
    "# sort them into subdirectories for ease of loading into Tensorflow\n",
    "\n",
    "sp = splitter.Splitter()\n",
    "sp.split_into_class_subdirectories(\n",
    "    src_dir_path=constants.get_validation_split_path(),\n",
    "    dest_dir_path=constants.get_validation_split_class_path(),\n",
    "    manifest_path=constants.get_validation_split_manifest_path(),\n",
    ")\n",
    "\n",
    "sp.split_into_class_subdirectories(\n",
    "    src_dir_path=constants.get_testing_split_path(),\n",
    "    dest_dir_path=constants.get_testing_split_class_path(),\n",
    "    manifest_path=constants.get_testing_split_manifest_path(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
